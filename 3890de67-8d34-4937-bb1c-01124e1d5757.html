<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>用 AI 和笔记对话 - Zji</title>
  <link rel="stylesheet" href="github-markdown.css">
  <link rel="stylesheet" href="style.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha512-z3gLpd7yknf1YoNbCzqRKc4qyor8gaKU1qmn+CShxbuBusANI9QpRohGBreCFkKxLhei6S9CQXFEbbKuqLg0DA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
  <link rel="stylesheet" href="atom-one-dark.min.css">
</head>
<body class="markdown-body">
  <main>
    <article>
      <h1 class="note-title">用 AI 和笔记对话</h1>
      <section><p>这不是教程，而是记录自己的理解。</p>
<h2 id="%E7%BC%98%E8%B5%B7">缘起</h2><p>我有在坚持做笔记，但是事件字段却没能坚持标注，因为这个工作流不算顺畅。毕竟呼出 QuickAdd 添加一条日记记录是很方便随意的，但是每日总结，提取这一天中值得被标注为事件的内容放入相应字段是复杂的。现在积累了快一年，这是个麻烦事儿。当然，因为我使用的是五年日记格式，所以以后随着回顾再慢慢提取标注也是完全可以的。</p>
<p>但想到了 AI，如果我能让 AI 帮我提取事件，是不是就……这个念头一旦产生，便不可收拾，所以折腾开始！</p>
<h2 id="%E6%A8%A1%E5%9E%8B">模型</h2><p>日记也算敏感数据，虽然其实没什么，但是肯定不想上传，所以我使用 LM Studio 搭建的本地大模型，不过这一点可能是本篇中最不重要的技术细节之一。</p>
<h2 id="%E5%B9%B2%E8%B4%A7">干货</h2><p>这里用到的主要概念：RAG——RAG（Retrieval-Augmented Generation，检索增强生成）。不做概念解读，直接说工作流程。</p>
<pre class="hljs-code-block"><code class="hljs mermaid" lang="mermaid">flowchart TB
  subgraph 嵌入
    note[笔记] ---> |提取文本|string[字符串] ---> |划分段落区块|chunk[文本区块]
  end
  subgraph 提问
    question[用户提问] ---> |文本嵌入|question_embedding[问题文本的嵌入向量]
  end
  subgraph 回答
    answer[最终回答] <--- AI[对话 AI 大模型] <--- prompt[提示词（用户问题）+上下文（相关笔记区块）] <--- match_chunk
  end
  
  question_embedding ---> |相似匹配|vector_database[向量库]
  chunk ---> |文本嵌入|vector_database
  vector_database ---> match_chunk[与问题匹配的 n 个笔记区块]</code></pre><p>使用 Mermaid 绘制，不好控制节点位置，请配合下方解读一起服用：</p>
<h3 id="%E5%B5%8C%E5%85%A5">嵌入</h3><ul>
<li>可以看做预处理，不是以笔记为单位，而是按章节或者段落，甚至句子为单位去划分的。比如我八百多篇笔记可能被划分为了 2600+ 个区块</li><li>对区块进行向量标记，就是计算机能理解的方式，用数值标记内容的含义。粗浅举例：如果 0 为纯黑色，255 为纯白色，128 就是灰色，这个数值就代表了它距离黒/白的距离，据此可以知道它更偏黑还是更偏白。复杂一点 RGB 颜色值就是具有三个维度的颜色向量。当然文本理解需要的维度更加复杂。</li><li>将如此处理后的内容存入数据库，以备查询</li></ul>
<h3 id="%E6%8F%90%E9%97%AE">提问</h3><ul>
<li>对问题先进行同上处理，即向量化</li><li>然后据此与数据库中内容比对，找出最相关的区块</li><li>根据设定，选出对应数量的最相关区块，提取对应内容，作为提问的上下文</li></ul>
<h3 id="%E5%9B%9E%E7%AD%94">回答</h3><ul>
<li>将提示词（系统提示词+用户的问题）和上下文（上一步选出的相关笔记内容）交给大模型</li><li>大模型据此作答。</li></ul>
<h2 id="%E5%B1%80%E9%99%90%E6%80%A7">局限性</h2><p>综上，我如果问：3 月 20 日发生了什么特别的事情吗？AI 应该可以比较好的回答，毕竟上下文应该会包含我那一天的笔记。</p>
<p>但如果我问：3 月份发生了哪些特别的事情。AI 很可能无法全面回答，因为它得到的上下文不可能是整个三月份的所有日记，被选出来的相关片段可能是 3 月份日记中有特别字样的内容。</p>
<p>如果我问： 3 月份我买了几次大米。因为事件不频繁，那么上下文基本可以涵盖所有事件，所以 AI 很可能给出正确答案。</p>
<p>即，<strong>可以与自己的笔记对话，但也不是那么行</strong>。</p>
<h2 id="%E5%BA%94%E7%94%A8">应用</h2><h3 id="%3Ca%20href=%22https%20//github.com/brianpetro/obsidian-smart-connections%22%20title=%22Smart%20Connections%22%20class=%22External-link%22%20target=%22_blank%22%3ESmart%20Connections%3C/a%3E"><a href="https://github.com/brianpetro/obsidian-smart-connections" title="Smart Connections" class="External-link" target="_blank">Smart Connections</a></h3><p>一个插件，利用向量数据库来分析笔记之间的联系程度，这比用双向链接或者标签、关键字来分析准确度要提升很多，虽然还不是真正的语义分析。但已经足够发现很多笔记之间的隐藏关联了，这比传统关系图谱更加有实用意义。在写作中，可以发现很多相关的，但是已经被自己遗忘的古老笔记。</p>
<p>当然它也可以对话，采用的就是上面我描述的操作逻辑。但默认不携带上下文，只有在你提出基于我的笔记（需要用英文 base my notes）时才会携带相关笔记片段，或者使用双方括号引用特定笔记，这时候携带的是整篇笔记。</p>
<p>刚安装插件时，它会生成向量数据库，速度比较慢。以后会在每次打开笔记库之后根据笔记更新时间来更新数据。</p>
<p>我觉得，它展示笔记间联系的功能最为惊艳。</p>
<h3 id="%3Ca%20href=%22https%20//github.com/logancyang/obsidian-copilothttps%20//github.com/logancyang/obsidian-copilot%22%20title=%22Copilot%22%20class=%22External-link%22%20target=%22_blank%22%3ECopilot%3C/a%3E"><a href="https://github.com/logancyang/obsidian-copilothttps://github.com/logancyang/obsidian-copilot" title="Copilot" class="External-link" target="_blank">Copilot</a></h3><p>这款插件测试的不多，逻辑上和上面差不多，但是侧重对话，为对话做了很多相关优化。并且作者野心也比较大，Copilot Plus 计划中是可以实现我在文初的需求的。但还需要时间等待其发展完善。</p>
<h3 id="%3Ca%20href=%22https%20//anythingllm.com/%22%20title=%22AnythingLLM%22%20class=%22External-link%22%20target=%22_blank%22%3EAnythingLLM%3C/a%3E"><a href="https://anythingllm.com/" title="AnythingLLM" class="External-link" target="_blank">AnythingLLM</a></h3><p>本地知识库工具，搭配 LM Studio 或者 Ollama 可以实现全本地知识库问答。工作流程和上面描述基本一致。</p>
<ul>
<li>索引速度相当快，相比上述插件简直无感</li><li>可以控制上下文携带的片段数量，但肯定不可能携带整库内容</li></ul>
<p>类似知识库工具还有很多，就不一一测试了。</p>
<h2 id="%E6%80%BB%E7%BB%93">总结</h2><p>所以所谓和笔记的问答，AI 只是根据上下文中和问题相关度较高的片段作答，应用场景限制是比较大的。但是灵活运用还是有一些很实用的场景。</p>
</section>
    </article>
  </main>
  <aside id="side-menu">
    <div class="toggle"><i class="fa-solid fa-bars"></i></div>
    <div class="aside-content">
      <div class="nav">
        <ul>
          <li class="home"><a href="/">Home</a></li>
          <li class="changelogs"><a href="/changelogs">Changelogs</a></li>
          <!-- <li class="coffee"><a href="https://afdian.net/a/daomishu" target="_blank">Coffee~ <i class="fa-solid fa-coffee"></i></a></li> -->
          <li class="gotop"><a href="#">Top</a></li>
        </ul>
      </div>
      <a class="coffee" href="https://afdian.com/a/daomishu" target="_blank" title="嘿，朋友！给我一杯咖啡~是的，是的，用来开启一天工作的咖啡~那玩意儿简直是我工作的电源。怎么样，难道你不期待我多鼓捣出一点奇奇怪怪的有趣儿玩意儿吗？">Buy me a Coffee~ <i class="fa-solid fa-coffee"></i></a>
      <div class="toc"><ul><li data-hash="%E7%BC%98%E8%B5%B7" style="margin-left: 1.5em"><a href="#%E7%BC%98%E8%B5%B7">缘起</a></li>
<li data-hash="%E6%A8%A1%E5%9E%8B" style="margin-left: 1.5em"><a href="#%E6%A8%A1%E5%9E%8B">模型</a></li>
<li data-hash="%E5%B9%B2%E8%B4%A7" style="margin-left: 1.5em"><a href="#%E5%B9%B2%E8%B4%A7">干货</a></li>
<li data-hash="%E5%B5%8C%E5%85%A5" style="margin-left: 3em"><a href="#%E5%B5%8C%E5%85%A5">嵌入</a></li>
<li data-hash="%E6%8F%90%E9%97%AE" style="margin-left: 3em"><a href="#%E6%8F%90%E9%97%AE">提问</a></li>
<li data-hash="%E5%9B%9E%E7%AD%94" style="margin-left: 3em"><a href="#%E5%9B%9E%E7%AD%94">回答</a></li>
<li data-hash="%E5%B1%80%E9%99%90%E6%80%A7" style="margin-left: 1.5em"><a href="#%E5%B1%80%E9%99%90%E6%80%A7">局限性</a></li>
<li data-hash="%E5%BA%94%E7%94%A8" style="margin-left: 1.5em"><a href="#%E5%BA%94%E7%94%A8">应用</a></li>
<li data-hash="%3Ca%20href=%22https%20//github.com/brianpetro/obsidian-smart-connections%22%20title=%22Smart%20Connections%22%20class=%22External-link%22%20target=%22_blank%22%3ESmart%20Connections%3C/a%3E" style="margin-left: 3em"><a href="#%3Ca%20href=%22https%20//github.com/brianpetro/obsidian-smart-connections%22%20title=%22Smart%20Connections%22%20class=%22External-link%22%20target=%22_blank%22%3ESmart%20Connections%3C/a%3E"><a href="https://github.com/brianpetro/obsidian-smart-connections" title="Smart Connections" class="External-link" target="_blank">Smart Connections</a></a></li>
<li data-hash="%3Ca%20href=%22https%20//github.com/logancyang/obsidian-copilothttps%20//github.com/logancyang/obsidian-copilot%22%20title=%22Copilot%22%20class=%22External-link%22%20target=%22_blank%22%3ECopilot%3C/a%3E" style="margin-left: 3em"><a href="#%3Ca%20href=%22https%20//github.com/logancyang/obsidian-copilothttps%20//github.com/logancyang/obsidian-copilot%22%20title=%22Copilot%22%20class=%22External-link%22%20target=%22_blank%22%3ECopilot%3C/a%3E"><a href="https://github.com/logancyang/obsidian-copilothttps://github.com/logancyang/obsidian-copilot" title="Copilot" class="External-link" target="_blank">Copilot</a></a></li>
<li data-hash="%3Ca%20href=%22https%20//anythingllm.com/%22%20title=%22AnythingLLM%22%20class=%22External-link%22%20target=%22_blank%22%3EAnythingLLM%3C/a%3E" style="margin-left: 3em"><a href="#%3Ca%20href=%22https%20//anythingllm.com/%22%20title=%22AnythingLLM%22%20class=%22External-link%22%20target=%22_blank%22%3EAnythingLLM%3C/a%3E"><a href="https://anythingllm.com/" title="AnythingLLM" class="External-link" target="_blank">AnythingLLM</a></a></li>
<li data-hash="%E6%80%BB%E7%BB%93" style="margin-left: 1.5em"><a href="#%E6%80%BB%E7%BB%93">总结</a></li></ul></div>
      <div class="meta"><small>created: 2024-11-10 08:31:13</small><br><small>updated: 2024-11-10 09:54:16</small></div>
    </div>
  </aside>
  <script src="script.js"></script>
  <foot>©2022~2025 稻米鼠. Last build at 2025-01-21 00:00:13</foot>
<script type="module">
      import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
      mermaid.initialize({ startOnLoad: true });
    </script>
</body>
</html>